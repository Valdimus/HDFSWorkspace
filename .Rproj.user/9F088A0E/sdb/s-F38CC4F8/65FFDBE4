{
    "collab_server" : "",
    "contents" : "# Author: Christophe NOUCHET\n# Email: nouchet.christophe@gmail.com\n# Date: 27/08/2017\n# How To Use: You must set HADOOP_HOME and HADOOP_BIN in your Renviron.site\n\n##' @name hadoop_command\n##' @description Get the bin path of Hadoop, HADOOP_HOME and HADOOP_BIN must be set in your Renviron.site\n##' @param command The hadoop command to get the absolute path of\n##' @return The absolute path of the Hadoop command\nhadoop_command <- function(command=\"\") {\n  hadoop_bin <- Sys.getenv(\"HADOOP_BIN\")\n  if(hadoop_bin == \"\"){\n    hadoop_bin <- \"/usr/bin\"\n  }\n  return(fix_path(file.path(hadoop_bin, command)))\n}\n\n##' @name hdfs_command\n##' @description Get the absolute path of the hdfs command\n##' @param options Option to git to the hdfs command\n##' @return The absolute path of the hdfs command\nhdfs_command <- function(options=\"\") {\n  return(hadoop_command(paste(\"hdfs\", options, sep=\" \")))\n}\n\n##' @name hdfs_dfs_command\n##' @description Get the absolute path of the hdfs command\n##' @param options Option to git to the dfs command\n##' @return The absolute path of the dfs command\nhdfs_dfs_command <- function(options) {\n  return(hdfs_command(paste(\"dfs\", options, sep=\" \")))\n}\n\n##' @name hdfs_dfs_ls\n##' @description Liste file on hadoop, get file size\n##' @param options Options to git to ls\n##' @return List of file\nhdfs_ls <- function(options=\"\") {\n  # Execute hdfs command\n  raw_file <- system(command = hdfs_dfs_command(paste(\"-ls\", options, \"|grep -v \\\"Found .*item.*\\\" | awk '{print $8, $5}'\", sep=\" \")), intern=TRUE)\n\n  # List of file\n  liste <- list()\n\n  # Get the file and their size\n  for(i in raw_file){\n    temp_list <- strsplit(i, \" \")\n    liste[[temp_list[[1]][1]]] <- temp_list[[1]][2]\n  }\n  return(liste)\n}\n\n##' @name readHDFSFile\n##' @description Get a file on HDFS\n##' @param filename The filename on HDFS to load\n##' @return file\nreadHDFSFile <- function(filename, options=\"rb\") {\n\n  # Check if the Rdata exist on HDFS\n  hdfs_files <- hdfs_ls(filename)\n  if(filename %in% names(hdfs_files)){\n    message(\"Read file '\", filename, \"' on HDFS\")\n\n    # Get the file size\n    file_size <- hdfs_files[[filename]]\n\n    # Use pv to have the progress of the loading\n    connection <- pipe(paste(hdfs_dfs_command(paste(\"-cat\",filename, sep=\" \")),\"| pv --size\",file_size, sep=\" \"), options)\n\n    return(connection)\n  }\n  else{\n    message(\"File '\", filename, \"' not found on HDFS\")\n    return(FALSE)\n  }\n}\n\n##' @name writeHDFSFile\n##' @description Save a file on HDFS\n##' @param filename The filename on HDFS to save\n##' @return file\nwriteHDFSFile <- function(filename, options=\"wb\") {\n  connection <- pipe(paste(\"pv |\", hdfs_dfs_command(\"-put -\"),filename, sep=\" \"), options)\n  return(connection)\n}\n\n\n##' @name hdfs_mkdir\n##' @param path Path to the directory to create\nhdfs_mkdir <- function(path) {\n  suppressWarnings(system(hdfs_dfs_command(paste(\"-mkdir\", path)), ignore.stderr = TRUE, ignore.stdout = TRUE, intern = TRUE))\n}\n",
    "created" : 1503847954191.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4262213722",
    "id" : "65FFDBE4",
    "lastKnownWriteTime" : 1503848066,
    "last_content_update" : 1503848066497,
    "path" : "~/RHDFSHome/R/hdfs.R",
    "project_path" : "R/hdfs.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 3,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}